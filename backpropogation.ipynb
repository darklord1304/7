{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27913c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************\n",
      "iteration: 0 :::: [[ 0.05011148 -0.9292999 ]]\n",
      "###output######## [[0.94988852 0.9292999 ]]\n",
      "**********************\n",
      "iteration: 1 :::: [[ 0.05010862 -0.92858931]]\n",
      "###output######## [[0.94989138 0.92858931]]\n",
      "**********************\n",
      "iteration: 2 :::: [[ 0.0501059 -0.9278663]]\n",
      "###output######## [[0.9498941 0.9278663]]\n",
      "**********************\n",
      "iteration: 3 :::: [[ 0.05010332 -0.92713056]]\n",
      "###output######## [[0.94989668 0.92713056]]\n",
      "**********************\n",
      "iteration: 4 :::: [[ 0.05010089 -0.9263818 ]]\n",
      "###output######## [[0.94989911 0.9263818 ]]\n",
      "**********************\n",
      "iteration: 5 :::: [[ 0.05009861 -0.9256197 ]]\n",
      "###output######## [[0.94990139 0.9256197 ]]\n",
      "**********************\n",
      "iteration: 6 :::: [[ 0.05009648 -0.92484396]]\n",
      "###output######## [[0.94990352 0.92484396]]\n",
      "**********************\n",
      "iteration: 7 :::: [[ 0.05009451 -0.92405425]]\n",
      "###output######## [[0.94990549 0.92405425]]\n",
      "**********************\n",
      "iteration: 8 :::: [[ 0.05009268 -0.92325022]]\n",
      "###output######## [[0.94990732 0.92325022]]\n",
      "**********************\n",
      "iteration: 9 :::: [[ 0.05009101 -0.92243155]]\n",
      "###output######## [[0.94990899 0.92243155]]\n",
      "**********************\n",
      "iteration: 10 :::: [[ 0.0500895  -0.92159786]]\n",
      "###output######## [[0.9499105  0.92159786]]\n",
      "**********************\n",
      "iteration: 11 :::: [[ 0.05008814 -0.92074881]]\n",
      "###output######## [[0.94991186 0.92074881]]\n",
      "**********************\n",
      "iteration: 12 :::: [[ 0.05008694 -0.919884  ]]\n",
      "###output######## [[0.94991306 0.919884  ]]\n",
      "**********************\n",
      "iteration: 13 :::: [[ 0.0500859  -0.91900307]]\n",
      "###output######## [[0.9499141  0.91900307]]\n",
      "**********************\n",
      "iteration: 14 :::: [[ 0.05008502 -0.91810561]]\n",
      "###output######## [[0.94991498 0.91810561]]\n",
      "**********************\n",
      "iteration: 15 :::: [[ 0.05008431 -0.91719122]]\n",
      "###output######## [[0.94991569 0.91719122]]\n",
      "**********************\n",
      "iteration: 16 :::: [[ 0.05008376 -0.91625947]]\n",
      "###output######## [[0.94991624 0.91625947]]\n",
      "**********************\n",
      "iteration: 17 :::: [[ 0.05008337 -0.91530995]]\n",
      "###output######## [[0.94991663 0.91530995]]\n",
      "**********************\n",
      "iteration: 18 :::: [[ 0.05008315 -0.91434219]]\n",
      "###output######## [[0.94991685 0.91434219]]\n",
      "**********************\n",
      "iteration: 19 :::: [[ 0.0500831  -0.91335576]]\n",
      "###output######## [[0.9499169  0.91335576]]\n",
      "**********************\n",
      "iteration: 20 :::: [[ 0.05008321 -0.91235018]]\n",
      "###output######## [[0.94991679 0.91235018]]\n",
      "**********************\n",
      "iteration: 21 :::: [[ 0.0500835  -0.91132498]]\n",
      "###output######## [[0.9499165  0.91132498]]\n",
      "**********************\n",
      "iteration: 22 :::: [[ 0.05008396 -0.91027965]]\n",
      "###output######## [[0.94991604 0.91027965]]\n",
      "**********************\n",
      "iteration: 23 :::: [[ 0.05008459 -0.90921369]]\n",
      "###output######## [[0.94991541 0.90921369]]\n",
      "**********************\n",
      "iteration: 24 :::: [[ 0.05008539 -0.90812657]]\n",
      "###output######## [[0.94991461 0.90812657]]\n",
      "**********************\n",
      "iteration: 25 :::: [[ 0.05008637 -0.90701777]]\n",
      "###output######## [[0.94991363 0.90701777]]\n",
      "**********************\n",
      "iteration: 26 :::: [[ 0.05008753 -0.90588672]]\n",
      "###output######## [[0.94991247 0.90588672]]\n",
      "**********************\n",
      "iteration: 27 :::: [[ 0.05008886 -0.90473286]]\n",
      "###output######## [[0.94991114 0.90473286]]\n",
      "**********************\n",
      "iteration: 28 :::: [[ 0.05009037 -0.90355561]]\n",
      "###output######## [[0.94990963 0.90355561]]\n",
      "**********************\n",
      "iteration: 29 :::: [[ 0.05009206 -0.90235436]]\n",
      "###output######## [[0.94990794 0.90235436]]\n",
      "**********************\n",
      "iteration: 30 :::: [[ 0.05009393 -0.90112851]]\n",
      "###output######## [[0.94990607 0.90112851]]\n",
      "**********************\n",
      "iteration: 31 :::: [[ 0.05009599 -0.89987741]]\n",
      "###output######## [[0.94990401 0.89987741]]\n",
      "**********************\n",
      "iteration: 32 :::: [[ 0.05009822 -0.89860042]]\n",
      "###output######## [[0.94990178 0.89860042]]\n",
      "**********************\n",
      "iteration: 33 :::: [[ 0.05010064 -0.89729688]]\n",
      "###output######## [[0.94989936 0.89729688]]\n",
      "**********************\n",
      "iteration: 34 :::: [[ 0.05010324 -0.89596609]]\n",
      "###output######## [[0.94989676 0.89596609]]\n",
      "**********************\n",
      "iteration: 35 :::: [[ 0.05010602 -0.89460736]]\n",
      "###output######## [[0.94989398 0.89460736]]\n",
      "**********************\n",
      "iteration: 36 :::: [[ 0.05010899 -0.89321996]]\n",
      "###output######## [[0.94989101 0.89321996]]\n",
      "**********************\n",
      "iteration: 37 :::: [[ 0.05011214 -0.89180315]]\n",
      "###output######## [[0.94988786 0.89180315]]\n",
      "**********************\n",
      "iteration: 38 :::: [[ 0.05011548 -0.89035617]]\n",
      "###output######## [[0.94988452 0.89035617]]\n",
      "**********************\n",
      "iteration: 39 :::: [[ 0.05011901 -0.88887825]]\n",
      "###output######## [[0.94988099 0.88887825]]\n",
      "**********************\n",
      "iteration: 40 :::: [[ 0.05012272 -0.88736858]]\n",
      "###output######## [[0.94987728 0.88736858]]\n",
      "**********************\n",
      "iteration: 41 :::: [[ 0.05012661 -0.88582635]]\n",
      "###output######## [[0.94987339 0.88582635]]\n",
      "**********************\n",
      "iteration: 42 :::: [[ 0.0501307  -0.88425071]]\n",
      "###output######## [[0.9498693  0.88425071]]\n",
      "**********************\n",
      "iteration: 43 :::: [[ 0.05013496 -0.88264082]]\n",
      "###output######## [[0.94986504 0.88264082]]\n",
      "**********************\n",
      "iteration: 44 :::: [[ 0.05013942 -0.88099579]]\n",
      "###output######## [[0.94986058 0.88099579]]\n",
      "**********************\n",
      "iteration: 45 :::: [[ 0.05014405 -0.87931472]]\n",
      "###output######## [[0.94985595 0.87931472]]\n",
      "**********************\n",
      "iteration: 46 :::: [[ 0.05014887 -0.87759669]]\n",
      "###output######## [[0.94985113 0.87759669]]\n",
      "**********************\n",
      "iteration: 47 :::: [[ 0.05015388 -0.87584077]]\n",
      "###output######## [[0.94984612 0.87584077]]\n",
      "**********************\n",
      "iteration: 48 :::: [[ 0.05015907 -0.87404599]]\n",
      "###output######## [[0.94984093 0.87404599]]\n",
      "**********************\n",
      "iteration: 49 :::: [[ 0.05016443 -0.87221137]]\n",
      "###output######## [[0.94983557 0.87221137]]\n",
      "**********************\n",
      "iteration: 5951 :::: [[ 0.01990245 -0.02269453]]\n",
      "###output######## [[0.98009755 0.02269453]]\n",
      "**********************\n",
      "iteration: 5952 :::: [[ 0.019901   -0.02269243]]\n",
      "###output######## [[0.980099   0.02269243]]\n",
      "**********************\n",
      "iteration: 5953 :::: [[ 0.01989955 -0.02269033]]\n",
      "###output######## [[0.98010045 0.02269033]]\n",
      "**********************\n",
      "iteration: 5954 :::: [[ 0.0198981  -0.02268823]]\n",
      "###output######## [[0.9801019  0.02268823]]\n",
      "**********************\n",
      "iteration: 5955 :::: [[ 0.01989664 -0.02268613]]\n",
      "###output######## [[0.98010336 0.02268613]]\n",
      "**********************\n",
      "iteration: 5956 :::: [[ 0.01989519 -0.02268403]]\n",
      "###output######## [[0.98010481 0.02268403]]\n",
      "**********************\n",
      "iteration: 5957 :::: [[ 0.01989374 -0.02268193]]\n",
      "###output######## [[0.98010626 0.02268193]]\n",
      "**********************\n",
      "iteration: 5958 :::: [[ 0.01989229 -0.02267983]]\n",
      "###output######## [[0.98010771 0.02267983]]\n",
      "**********************\n",
      "iteration: 5959 :::: [[ 0.01989084 -0.02267773]]\n",
      "###output######## [[0.98010916 0.02267773]]\n",
      "**********************\n",
      "iteration: 5960 :::: [[ 0.01988939 -0.02267563]]\n",
      "###output######## [[0.98011061 0.02267563]]\n",
      "**********************\n",
      "iteration: 5961 :::: [[ 0.01988794 -0.02267353]]\n",
      "###output######## [[0.98011206 0.02267353]]\n",
      "**********************\n",
      "iteration: 5962 :::: [[ 0.01988649 -0.02267143]]\n",
      "###output######## [[0.98011351 0.02267143]]\n",
      "**********************\n",
      "iteration: 5963 :::: [[ 0.01988504 -0.02266934]]\n",
      "###output######## [[0.98011496 0.02266934]]\n",
      "**********************\n",
      "iteration: 5964 :::: [[ 0.01988359 -0.02266724]]\n",
      "###output######## [[0.98011641 0.02266724]]\n",
      "**********************\n",
      "iteration: 5965 :::: [[ 0.01988215 -0.02266515]]\n",
      "###output######## [[0.98011785 0.02266515]]\n",
      "**********************\n",
      "iteration: 5966 :::: [[ 0.0198807  -0.02266305]]\n",
      "###output######## [[0.9801193  0.02266305]]\n",
      "**********************\n",
      "iteration: 5967 :::: [[ 0.01987925 -0.02266096]]\n",
      "###output######## [[0.98012075 0.02266096]]\n",
      "**********************\n",
      "iteration: 5968 :::: [[ 0.0198778  -0.02265886]]\n",
      "###output######## [[0.9801222  0.02265886]]\n",
      "**********************\n",
      "iteration: 5969 :::: [[ 0.01987636 -0.02265677]]\n",
      "###output######## [[0.98012364 0.02265677]]\n",
      "**********************\n",
      "iteration: 5970 :::: [[ 0.01987491 -0.02265468]]\n",
      "###output######## [[0.98012509 0.02265468]]\n",
      "**********************\n",
      "iteration: 5971 :::: [[ 0.01987346 -0.02265258]]\n",
      "###output######## [[0.98012654 0.02265258]]\n",
      "**********************\n",
      "iteration: 5972 :::: [[ 0.01987202 -0.02265049]]\n",
      "###output######## [[0.98012798 0.02265049]]\n",
      "**********************\n",
      "iteration: 5973 :::: [[ 0.01987057 -0.0226484 ]]\n",
      "###output######## [[0.98012943 0.0226484 ]]\n",
      "**********************\n",
      "iteration: 5974 :::: [[ 0.01986913 -0.02264631]]\n",
      "###output######## [[0.98013087 0.02264631]]\n",
      "**********************\n",
      "iteration: 5975 :::: [[ 0.01986768 -0.02264422]]\n",
      "###output######## [[0.98013232 0.02264422]]\n",
      "**********************\n",
      "iteration: 5976 :::: [[ 0.01986624 -0.02264213]]\n",
      "###output######## [[0.98013376 0.02264213]]\n",
      "**********************\n",
      "iteration: 5977 :::: [[ 0.01986479 -0.02264004]]\n",
      "###output######## [[0.98013521 0.02264004]]\n",
      "**********************\n",
      "iteration: 5978 :::: [[ 0.01986335 -0.02263796]]\n",
      "###output######## [[0.98013665 0.02263796]]\n",
      "**********************\n",
      "iteration: 5979 :::: [[ 0.0198619  -0.02263587]]\n",
      "###output######## [[0.9801381  0.02263587]]\n",
      "**********************\n",
      "iteration: 5980 :::: [[ 0.01986046 -0.02263378]]\n",
      "###output######## [[0.98013954 0.02263378]]\n",
      "**********************\n",
      "iteration: 5981 :::: [[ 0.01985902 -0.02263169]]\n",
      "###output######## [[0.98014098 0.02263169]]\n",
      "**********************\n",
      "iteration: 5982 :::: [[ 0.01985757 -0.02262961]]\n",
      "###output######## [[0.98014243 0.02262961]]\n",
      "**********************\n",
      "iteration: 5983 :::: [[ 0.01985613 -0.02262752]]\n",
      "###output######## [[0.98014387 0.02262752]]\n",
      "**********************\n",
      "iteration: 5984 :::: [[ 0.01985469 -0.02262544]]\n",
      "###output######## [[0.98014531 0.02262544]]\n",
      "**********************\n",
      "iteration: 5985 :::: [[ 0.01985324 -0.02262335]]\n",
      "###output######## [[0.98014676 0.02262335]]\n",
      "**********************\n",
      "iteration: 5986 :::: [[ 0.0198518  -0.02262127]]\n",
      "###output######## [[0.9801482  0.02262127]]\n",
      "**********************\n",
      "iteration: 5987 :::: [[ 0.01985036 -0.02261919]]\n",
      "###output######## [[0.98014964 0.02261919]]\n",
      "**********************\n",
      "iteration: 5988 :::: [[ 0.01984892 -0.0226171 ]]\n",
      "###output######## [[0.98015108 0.0226171 ]]\n",
      "**********************\n",
      "iteration: 5989 :::: [[ 0.01984748 -0.02261502]]\n",
      "###output######## [[0.98015252 0.02261502]]\n",
      "**********************\n",
      "iteration: 5990 :::: [[ 0.01984604 -0.02261294]]\n",
      "###output######## [[0.98015396 0.02261294]]\n",
      "**********************\n",
      "iteration: 5991 :::: [[ 0.0198446  -0.02261086]]\n",
      "###output######## [[0.9801554  0.02261086]]\n",
      "**********************\n",
      "iteration: 5992 :::: [[ 0.01984316 -0.02260878]]\n",
      "###output######## [[0.98015684 0.02260878]]\n",
      "**********************\n",
      "iteration: 5993 :::: [[ 0.01984172 -0.0226067 ]]\n",
      "###output######## [[0.98015828 0.0226067 ]]\n",
      "**********************\n",
      "iteration: 5994 :::: [[ 0.01984028 -0.02260462]]\n",
      "###output######## [[0.98015972 0.02260462]]\n",
      "**********************\n",
      "iteration: 5995 :::: [[ 0.01983884 -0.02260254]]\n",
      "###output######## [[0.98016116 0.02260254]]\n",
      "**********************\n",
      "iteration: 5996 :::: [[ 0.0198374  -0.02260046]]\n",
      "###output######## [[0.9801626  0.02260046]]\n",
      "**********************\n",
      "iteration: 5997 :::: [[ 0.01983596 -0.02259839]]\n",
      "###output######## [[0.98016404 0.02259839]]\n",
      "**********************\n",
      "iteration: 5998 :::: [[ 0.01983453 -0.02259631]]\n",
      "###output######## [[0.98016547 0.02259631]]\n",
      "**********************\n",
      "iteration: 5999 :::: [[ 0.01983309 -0.02259423]]\n",
      "###output######## [[0.98016691 0.02259423]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "inputNeurons=2 \n",
    "hiddenlayerNeurons=4 \n",
    "outputNeurons=2 \n",
    "iteration=6000\n",
    "\n",
    "input = np.random.randint(1,5,inputNeurons) \n",
    "output = np.array([1.0,0.0]) \n",
    "hidden_layer=np.random.rand(1,hiddenlayerNeurons)\n",
    "\n",
    "hidden_biass=np.random.rand(1,hiddenlayerNeurons) \n",
    "output_bias=np.random.rand(1,outputNeurons) \n",
    "hidden_weights=np.random.rand(inputNeurons,hiddenlayerNeurons) \n",
    "output_weights=np.random.rand(hiddenlayerNeurons,outputNeurons)\n",
    "\n",
    "def sigmoid (layer):\n",
    "    return 1/(1 + np.exp(-layer))\n",
    "\n",
    "\n",
    "def gradient(layer): \n",
    "    return layer*(1-layer)\n",
    "\n",
    "for i in range(iteration):\n",
    "\n",
    "    hidden_layer=np.dot(input,hidden_weights) \n",
    "    hidden_layer=sigmoid(hidden_layer+hidden_biass)\n",
    "\n",
    "    output_layer=np.dot(hidden_layer,output_weights) \n",
    "    output_layer=sigmoid(output_layer+output_bias)\n",
    "\n",
    "    error = (output-output_layer) \n",
    "    gradient_outputLayer=gradient(output_layer)\n",
    "    error_terms_output=gradient_outputLayer * error \n",
    "    error_terms_hidden=gradient(hidden_layer)*np.dot(error_terms_output,output_weights.T)\n",
    "\n",
    "    gradient_hidden_weights = np.dot(input.reshape(inputNeurons,1),error_terms_hidden.reshape(1,hiddenlayerNeurons))\n",
    "    gradient_ouput_weights = np.dot(hidden_layer.reshape(hiddenlayerNeurons,1),error_terms_output.reshape(1,outputNeurons))\n",
    "\n",
    "    hidden_weights = hidden_weights + 0.05*gradient_hidden_weights \n",
    "    output_weights = output_weights + 0.05*gradient_ouput_weights \n",
    "    if i<50 or i>iteration-50:\n",
    "        print(\"**********************\") \n",
    "        print(\"iteration:\",i,\"::::\",error) \n",
    "        print(\"###output########\",output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd43d8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
